{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys,os\n",
    "# Root directory of the project\n",
    "ROOT_DIR = os.path.abspath(\"../../\")\n",
    "\n",
    "sys.path.append(ROOT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import models\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from dataset.dataset_ImagePrivacy import full_transform\n",
    "from networks.channel_grouping import load_cls_model\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "print(os.getpid())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the model and hook the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_blobs = []\n",
    "def hook_feature(module, input, output):\n",
    "    features_blobs.append(np.squeeze(output.data.cpu().numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model():\n",
    "    model_path = '../../models/ResNet4IP.pth'\n",
    "    \n",
    "    model = load_cls_model(class_num=2, pretrained=False)\n",
    "    model = model.to(device)\n",
    "    \n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    model.eval()\n",
    "    \n",
    "    features_names = ['layer4','avgpool'] # the last conv layer of the resnet101\n",
    "    for name in features_names:\n",
    "        model._modules.get(name).register_forward_hook(hook_feature)\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_model = load_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "partition = 1\n",
    "partition = str(partition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '../../../../data/image_privacy/exp/'\n",
    "data_file = data_dir + 'partition'+ partition + '/train.csv'\n",
    "\n",
    "data_list = pd.read_csv(data_file)\n",
    "imgs_name = data_list['img_name'].values.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visulization of CAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from torch.nn import functional as F\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the softmax weight\n",
    "params = list(cls_model.parameters())\n",
    "weight_softmax = params[-2].data.numpy()\n",
    "weight_softmax[weight_softmax<0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def returnCAM(feature_conv, weight_softmax, class_idx):\n",
    "    # generate the class activation maps upsample to 256x256\n",
    "    size_upsample = (256, 256)\n",
    "    nc, h, w = feature_conv.shape\n",
    "    output_cam = []\n",
    "    for idx in class_idx:\n",
    "        cam = weight_softmax[class_idx].dot(feature_conv.reshape((nc, h*w)))\n",
    "        cam = cam.reshape(h, w)\n",
    "        cam = cam - np.min(cam)\n",
    "        cam_img = cam / np.max(cam)\n",
    "        cam_img = np.uint8(255 * cam_img)\n",
    "        output_cam.append(cv2.resize(cam_img, size_upsample))\n",
    "    return output_cam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# img_name = random.choice(imgs)\n",
    "# img_name = img_dir + img_name\n",
    "\n",
    "img_name = random.choice(imgs_name)\n",
    "\n",
    "img = Image.open(img_name)\n",
    "input_img = full_transform(img).unsqueeze(0)\n",
    "\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# forward pass, the result is the probability of [private, public]\n",
    "features_blobs = []\n",
    "logit = cls_model.forward(input_img)\n",
    "h_x = F.softmax(logit, 1).data.squeeze()\n",
    "probs, idx = h_x.sort(0, True)\n",
    "probs = probs.numpy()\n",
    "idx = idx.numpy()\n",
    "print(probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('RESULT ON ' + img_name)\n",
    "\n",
    "# generate class activation mapping\n",
    "print('Class activation map is saved as cam.jpg')\n",
    "CAMs = returnCAM(features_blobs[0], weight_softmax, [idx[0]])\n",
    "\n",
    "# render the CAM and output\n",
    "img = cv2.imread(img_name)\n",
    "height, width, _ = img.shape\n",
    "heatmap = cv2.applyColorMap(cv2.resize(CAMs[0],(width, height)), cv2.COLORMAP_JET)\n",
    "result = heatmap * 0.4 + img * 0.5\n",
    "# cv2.imwrite('cam.jpg', result)\n",
    "\n",
    "b,g,r=cv2.split(result)\n",
    "img_rgb = cv2.merge([r,g,b])\n",
    "\n",
    "plt.imshow(img_rgb/255)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get coordinate of peak response  (features for each channel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_features = []\n",
    "\n",
    "for i in range(2048): # corresponding to the channels\n",
    "    channel_features.append([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for img_name in imgs_name:\n",
    "    try:\n",
    "        img = Image.open(img_name).convert('RGB') # convert gray to rgb\n",
    "        input_img = full_transform(img).unsqueeze(0).to(device)\n",
    "\n",
    "    #     plt.imshow(img)\n",
    "    #     plt.show()\n",
    "\n",
    "        features_blobs = []\n",
    "        logit = cls_model.forward(input_img)\n",
    "\n",
    "        for i, channel in enumerate(features_blobs[0]):\n",
    "\n",
    "            tx, ty =  np.where(channel==channel.max())\n",
    "            tx, ty = tx[0], ty[0]\n",
    "\n",
    "            channel_features[i].append(tx)\n",
    "            channel_features[i].append(ty)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(img_name)\n",
    "\n",
    "channel_features = np.array(channel_features)\n",
    "np.save('./channel_features.npy', channel_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(channel_features.shape) # channel_feature: [2048, 2 * sizeof_train_images]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## channel clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_features = np.load('./channel_features.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "part_nums = list(range(2,14,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "part_nums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for part_num in part_nums:\n",
    "    part_index = KMeans(n_clusters=part_num, random_state=9).fit_predict(channel_features)\n",
    "    np.save('./grouping_result/channel_cluster_' + str(part_num) + '.npy', part_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
