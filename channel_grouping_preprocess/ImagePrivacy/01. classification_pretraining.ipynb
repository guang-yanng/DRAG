{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys,os\n",
    "# Root directory of the project\n",
    "ROOT_DIR = os.path.abspath(\"../../\")\n",
    "\n",
    "sys.path.append(ROOT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset.dataset_ImagePrivacy import IPDataset_FromFileList, full_transform\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "partition = 1\n",
    "partition = str(partition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '../../../../data/image_privacy/'\n",
    "train_images = data_dir + 'exp/partition'+ partition + '/train.csv'\n",
    "val_images = data_dir + 'exp/partition'+ partition + '/val.csv'\n",
    "test_images = data_dir + 'exp/partition'+ partition + '/test.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = IPDataset_FromFileList(train_images, full_transform)\n",
    "val_data = IPDataset_FromFileList(val_images,full_transform)\n",
    "test_data = IPDataset_FromFileList(test_images, full_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset=train_data, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(dataset=val_data, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_data, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from networks.channel_grouping import load_cls_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_model = load_cls_model(class_num=2, pretrained=True)\n",
    "cls_model = cls_model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deal with the unbalanced dataset\n",
    "\n",
    "private_nums, public_nums = train_data.labels.count(0), train_data.labels.count(1)\n",
    "sample_class_count  = torch.Tensor([private_nums, public_nums])\n",
    "\n",
    "class_weight = sample_class_count.float() /train_data.__len__()\n",
    "class_weight = 1.-class_weight\n",
    "\n",
    "class_weight = class_weight.to(device)\n",
    "print(class_weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 50\n",
    "learning_rate = 1e-4\n",
    "\n",
    "momentum = 0.9\n",
    "weight_decay = 1e-7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = nn.CrossEntropyLoss(weight=class_weight)\n",
    "optimizer = torch.optim.SGD(cls_model.parameters(), lr=learning_rate, momentum=momentum)\n",
    "# optimizer = torch.optim.Adam(cls_model.parameters(), lr=learning_rate,weight_decay=weight_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler_cls = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(data_loader):\n",
    "    # validating\n",
    "    print('validating')\n",
    "    cls_model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    TP,FP,FN,TN = 0,0,0,0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(data_loader, 0):\n",
    "            target = data[0].to(device)\n",
    "            img = data[1].to(device)\n",
    "            outputs = cls_model(img)\n",
    "\n",
    "            predicted = torch.argmax(outputs.data,-1)\n",
    "\n",
    "            total += target.size(0)\n",
    "            correct += (predicted == target).sum().item()\n",
    "\n",
    "            TP += ((target == 0) & (predicted == 0)).sum().item()\n",
    "            FP += ((target == 0) & (predicted == 1)).sum().item()\n",
    "            FN += ((target == 1) & (predicted == 0)).sum().item()\n",
    "            TN += ((target == 1) & (predicted == 1)).sum().item()\n",
    "\n",
    "            del(outputs)\n",
    "            del(predicted)\n",
    "            \n",
    "    acc = 100. * correct / total\n",
    "    \n",
    "    if data_loader == test_loader:\n",
    "\n",
    "        print('testing accuracy：%.3f%%' % (acc))\n",
    "\n",
    "    else:\n",
    "        print('validating accuracy：%.3f%%' % (acc))\n",
    "\n",
    "    try:\n",
    "\n",
    "        #private metrics\n",
    "        p1 = TP / (TP + FP)\n",
    "        r1 = TP / (TP + FN)\n",
    "        f1 = (2 * p1 * r1) / (p1 + r1)\n",
    "\n",
    "        #public metrics\n",
    "        p2 = TN / (TN + FN)\n",
    "        r2 = TN / (TN + FP)\n",
    "        f2 = (2 * p2 * r2) / (p2 + r2)\n",
    "\n",
    "        print('===========================')\n",
    "\n",
    "        print('private class metrics:')\n",
    "        \n",
    "        print('precision, recall, f1:')\n",
    "        print('%.3f%%\\t%.3f%%\\t%.3f' % (p1 * 100, r1 * 100, f1))\n",
    "\n",
    "        print('===========================')\n",
    "        \n",
    "        print('public class metrics:')\n",
    "        \n",
    "        print('precision, recall, f1:')\n",
    "        print('%.3f%%\\t%.3f%%\\t%.3f' % (p2 * 100, r2 * 100, f2))\n",
    "        \n",
    "        print('===========================')\n",
    "\n",
    "\n",
    "#         print('===========================')\n",
    "#         print((TP+TN)/(TP+TN+FP+FN))\n",
    "#         print('===========================')\n",
    "\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print('TP, FP, TN, FN: ')\n",
    "        print(TP, FP, TN, FN)\n",
    "\n",
    "    \n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "epoch_start = 0\n",
    "\n",
    "for epoch in range(epoch_start, (epoch_start+epochs)):\n",
    "    print('training')\n",
    "    cls_model.train()\n",
    "    running_loss, count, acc = 0., 0, 0.\n",
    "    print(time.asctime())\n",
    "    \n",
    "    print('current learning rate:')\n",
    "    print(optimizer.param_groups[0]['lr'])\n",
    "    \n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        target = data[0].to(device)\n",
    "        img = data[1].to(device)\n",
    "        outputs = cls_model(img)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss = loss_func(outputs, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics     \n",
    "        running_loss += loss.item()\n",
    "        if i % 50 == 49:    # print every several mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / (i + 1)))\n",
    "\n",
    "    val_acc = validate(val_loader)\n",
    "    test_acc = validate(test_loader)\n",
    "    \n",
    "    scheduler_cls.step(val_acc)\n",
    "\n",
    "    val_acc = round(val_acc,3)\n",
    "    test_acc = round(test_acc,3)\n",
    "        \n",
    "    # save checkpoints\n",
    "    print('saving checkpoints....')\n",
    "\n",
    "    model_path = '../models/ResNet4IP({})_{}_{}.pth'.format(epoch, val_acc, test_acc)\n",
    "    torch.save(cls_model.state_dict(), model_path)\n",
    "\n",
    "            \n",
    "print('Finished Training')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = '../models/ResNet4IP.pth'\n",
    "cls_model.load_state_dict(torch.load(model_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validate(val_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
